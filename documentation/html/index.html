<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>dfh.grammar.Grammar</title>
<link rel="icon" type="image/png" href="/dfh.png" />
<link href="../css/dfh.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="../scripts/pageutils.js"></script>
<script type="text/javascript" src="headers.json"></script>
</head>
<body onLoad="dfh.prepare('Grammar', 'dfh.grammar')">
	<img width="500px" id="grammar_tree"
		alt="Picture of a grammar tree as produced by MatchToDot. If you don't see a picture, your browser can't show in-line svg graphics. Sorry."
		src="img/grammar_logo.svg"
		style="display: block; margin-left: auto; margin-right: auto; margin-bottom: 0">
	<h1>Grammar</h1>
	<p>
		The
		<code>dfh.grammar</code>
		library is a pattern matching library for Java inspired by the
		enhanced regular expression facilities provided by Perl 5.10+ and Perl
		6. The basic functionality in the Perl 5.10+ regex engine is <a
			href="http://perldoc.perl.org/perlre.html">awesome</a> in itself, but
		the syntactic sugar provide by <a
			href="http://search.cpan.org/search?query=Regexp%3A%3AGrammars&mode=module">Regexp::Grammar</a>
		is another order of magnitude better still, and <a
			href="http://dev.perl.org/perl6/doc/design/exe/E05.html">Perl 6</a>
		is still more fabulous. I have long loved these character pattern
		matching facilities and craved the same for Java, the language which
		is my bread and butter. This is not to knock Java. Java's character
		class syntax is fabulous. I love being able to combine character
		classes like sets. But due to double escaping Java regular expressions
		of any size are unreadable, and there's no way to make them recursive.
		Compositionality may be achieved to some extent by adding patterns
		together like strings, but I wanted more. Since I prefer coding to
		Googling for code, I decided to write my own improvement on Java
		regexes. This library is the product of this labor of obsession.
	</p>
	<span id="toc"></span>
	<h2>The Basic Idea</h2>
	<div>
		The image above was produced by taking the grammar
		<pre>&lt;ROOT&gt; = ~&lt;b&gt; &lt;g&gt; &lt;r&gt;?+ &lt;a&gt; &lt;m&gt;{2} &lt;a&gt; &lt;r&gt; ~&lt;b&gt;

   &lt;a&gt; = "a"
   &lt;b&gt; = / $ | ^ /x
   &lt;g&gt; = /g/i
   &lt;m&gt; = "m"
   &lt;r&gt; = "r"</pre>
		and applying it to the word <i>Grammar</i>. <span class="fn">Specifically,
			I combined the two using the <code>MatchToDot</code> application
			included with the <code>dfh.grammar</code> distribution, passing that
			through <a href="http://www.graphviz.org/">GraphViz</a> and rescaling
			the image a bit with <a href="http://inkscape.org/">Inkscape</a>.
		</span> As you can see, a grammar looks a lot like a <a
			href="http://en.wikipedia.org/wiki/Backus%E2%80%93Naur_Form">BNF
			grammar</a>. It consists of a list of named rules. Rule names are
		sequences of characters in the
		<code>\w</code>
		class enclosed in angle brackets. Each line in the grammar consists of
		a rule name, an equals sign, and a rule definition.<span class="fn">Or
			a blank line or a comment beginning with <code>#</code>. Rule
			definitions may also end in a comment.
		</span> The rule definition consists of one or more elements optionally
		modified in various ways. A leading
		<code>~</code>
		or
		<code>!</code>
		marks a forward-looking zero-width assertion.<span class="fn">Variable
			width backwards assertions are indicated by <code>~-</code> or <code>!-</code>;
			and for symmetry one may use <code>~+</code> and <code>!+</code> to
			indicate forward assertions. Though the backwards assertions native
			to <code>dfh.grammar</code> are variable width, unlike those of <code>java.lang.regex.Pattern</code>,
			they do have limitations that don't pertain to forward assertions.
			See <a href="syntax.html">syntax</a>. Of course, one may define a
			terminal rule that provides a <code>java.util.regex.Pattern</code>
			zero-width assertion, though the grammar will not be able to
			recognize it as such.
		</span> Trailing suffixes familiar from Perl-style regular expressions --
		<code>*?</code>
		,
		<code>{1,2}</code>
		, etc. -- indicate repetitions. Constituents may be grouped with angle
		brackets --
		<code> [ &lt;a&gt; &lt;b&gt; ]+ </code>
		. Alternates are marked with
		<code>|</code>
		. And so forth.
	</div>
	<div>
		The atomic constituents of rules are literals, marked with single or
		double quotes, and regular expressions.<span class="fn">Or
			arbitrary extensions of the <code>dfh.grammar.Rule</code>, as is
			explained elsewhere.
		</span>
	</div>
	<div>
		Among the rules is a special rule called
		<code>&lt;ROOT&gt;</code>
		. For the grammar to match a character sequence the root rule must
		match. Constituent rules are invoked as needed by other rules.
	</div>
	<div>
		The net result is an object that matches much like a
		<code>java.util.regex.Pattern</code>
		. For example, the grammar above is identical to the regex
		<pre>
  \b(?i:g)\br?+am{2}ar\b</pre>
	</div>
	<h2>How it works</h2>
	<p>
		This is roughly the algorithm in a nutshell: The grammar compiles into
		what I gather from poking about in Wikipedia is a <a
			href="http://en.wikipedia.org/wiki/Recursive_descent_parser">recursive
			descent parser</a>.<span class="fn">The <code>dfh.grammar</code>
			formalism bears a resemblance to <a
			href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing
				expression grammar</a>, though its rules, aside from the first, are not
			ordered, and its grammars may be ambiguous. It uses a caching
			algorithm similar to that of <a href="http://bford.info/packrat/">packrat
				parsers</a>, but it only stores the success or failure of matching for
			non-terminal rules. For terminal rules, the entire match is cached.
			This accelerates parsing without require exponential memory.
		</span> Basically this is a finite state automaton that consumes symbols as
		it moves over a symbol sequence. This automaton examines symbols in
		two streams: the character sequence you give it and a reversed version
		of this sequence for lookbehinds. To accelerate matching, terminal
		matches are cached. Also, all rules cache offsets at which they fail
		to match so they never attempt to match at such offsets twice.
		Functionally identical rules share caches, so, for example, a literal
		sub-rule in one rule will not attempt to match where an identical
		literal from another rule has already been tried.
	</p>
	<h2>Why?</h2>
	<div>
		So if grammars are basically regexes, why not use regexes? Well, for
		simple patterns you probably do want regexes. You can type them in
		faster and they will match faster. You want a grammar when the pattern
		is complex, recursive, or requires arbitrary tests not expressible in
		the standard regular expression syntax. The advantages of a grammar
		are
		<ul>
			<li>Because they are built up compositionally, they are easier
				to read.
			<li>You can iterate over all possible matches of a patter
				against a sequence, not just non-overlapping matches.
			<li>You can create your own arbitrary extensions to <code>dfh.grammar.Rule</code>,
				allowing matches against character sequences conditioned on
				arbitrary meta-data, such as part of speech tags inferred by a
				separate POS tagger.
			<li>They can handle recursive rules.
			<li>They can take arbitrary post-match conditions such as <pre>&lt;a&gt; = /\b\d++/ (less_than_500)</pre>
			<li>They allow finer control of backtracking, potentially making
				excessively complex pattern matching tractable.
			<li>They provide debugging facilities that record a trace of the
				matching process.
			<li>The match object returned records the entire sequence of
				rules used in the match and the exact offsets at which each sub-rule
				matched.
			<li>The match object has methods that facilitate extracting
				information from it as you would from other tree-structured data
				such as XML.
		</ul>
	</div>
	<h2>Examples</h2>
	<div>
		The examples below are just that: examples. For a more complete survey
		of how grammars can be instantiated, manipulated, and used, see the
		code in the test directory,
		<code>/</code>
		, or the examples directory,
		<code>examples/</code>
		.
	</div>
	<h3>Matching</h3>
	<div>
		As with
		<code>java.util.regex.Matcher</code>
		, the basic methods are
		<code>match</code>
		,
		<code>find</code>
		, and
		<code>lookingAt</code>
		, where the first must match the entire character sequence, the
		second, some prefix of the sequence, and the third, anywhere.
	</div>
	<div>
		<pre>		String[] rules = {
				"&lt;ROOT&gt; = &lt;c&gt; &lt;d&gt;",
				"&lt;c&gt; = &lt;a&gt;++",
				"&lt;d&gt; = &lt;a&gt; &lt;b&gt;",
				"&lt;a&gt; = /a/",
				"&lt;b&gt; = /b/",
		};
		Grammar g = new Grammar(rules);
		String s = "aab";
		Matcher m = g.lookingAt(s);
		Match n = m.match();
		System.out.println(n);
		System.out.println(n.group());</pre>
		produces
		<pre class="results">(&lt;c&gt; &lt;d&gt;: 0, 3 [(&lt;a&gt;+: 0, 1 [(/a/: 0, 1)]), (&lt;a&gt; &lt;b&gt;: 1, 3 [(/a/: 1, 2), (/b/: 2, 3)])])
aab</pre>
		The stringification of
		<code>dfh.grammar.Match</code>
		itself has the grammar
		<pre>&lt;stringication&gt; = "(" &lt;rule_id&gt; ": " &lt;offsets&gt; [ "[" &lt;submatches&gt;"]" ]? ")"
   &lt;submatches&gt; = &lt;stringification&gt; [ ", " &lt;stringification&gt; ]*</pre>
	</div>
	<h3>Iterating over Matches</h3>
	<div>
		As with
		<code>java.util.regex.Matcher</code>
		, a
		<code>dfh.grammar.Matcher</code>
		behaves as an iterator over matches.
	</div>
	<div>
		<pre>		String[] rules = {
				"&lt;ROOT&gt; = &lt;a&gt;+ &lt;a&gt;+",
				"&lt;a&gt; = /a/",
		};
		Grammar g = new Grammar(rules);
		String s = "aaa";
		Options opt = new Options();
		opt.allowOverlap(true);
		Matcher m = g.find(s, opt);
		Match n;
		while ((n = m.match()) != null)
			System.out.println(n);</pre>
		produces
		<pre class="results">(&lt;a&gt;+ &lt;a&gt;+: 0, 3 [(&lt;a&gt;+: 0, 2 [(/a/: 0, 1), (/a/: 1, 2)]), (&lt;a&gt;+: 2, 3 [(/a/: 2, 3)])])
(&lt;a&gt;+ &lt;a&gt;+: 0, 3 [(&lt;a&gt;+: 0, 1 [(/a/: 0, 1)]), (&lt;a&gt;+: 1, 3 [(/a/: 1, 2), (/a/: 2, 3)])])
(&lt;a&gt;+ &lt;a&gt;+: 0, 2 [(&lt;a&gt;+: 0, 1 [(/a/: 0, 1)]), (&lt;a&gt;+: 1, 2 [(/a/: 1, 2)])])
(&lt;a&gt;+ &lt;a&gt;+: 1, 3 [(&lt;a&gt;+: 1, 2 [(/a/: 1, 2)]), (&lt;a&gt;+: 2, 3 [(/a/: 2, 3)])])</pre>
	</div>
	<div>Note that the matcher in this case is iterating over all
		possible ways the grammar could match the given string, not just the
		non-overlapping matches. This is because of this bit:</div>
	<pre>		Options opt = new Options();
		opt.allowOverlap(true);
		Matcher m = g.find(s, opt);</pre>
	<div>
		This is the general way one modifies the behavior of a
		<code>dfh.grammar.Matcher</code>
		, other than by changing the method of
		<code>dfh.grammar.Grammar</code>
		that produced it. You instantiate a
		<code>dfh.grammar.Options</code>
		object and then change its properties with its accessors.<span
			class="fn">For the sake of brevity I did not use the JavaBean
			spec for accessors.</span> Once a matcher has been created, it is
		independent of the
		<code>Options</code>
		object used in its creation. You may change this however you like and
		it will not affect the behavior of the
		<code>Matcher</code>
		.
	</div>
	<h3>Applying Arbitrary Conditions to Rules</h3>
	<div>One of the more powerful features of grammars is that you
		can apply arbitrary conditions to rules, validating sub-portions of a
		match mid-match.</div>
	<div>
		<pre>                String[] rules = { 
                                "&lt;ROOT&gt; = &lt;year&gt; '/' &lt;month&gt; '/' &lt;day&gt; (is_date)",
                                "&lt;year&gt; = /\\b\\d{4}/",
                                "&lt;month&gt; = /\\d{1,2}/",
                                "&lt;day&gt; = /\\d{1,2}/",
                };
                Grammar g = new Grammar(rules);
                g.defineCondition("is_date", new Condition() {
                        @Override
                        public boolean passes(Match n, Matcher m, CharSequence s) {
                                int year = parse(s, n.children()[0]);
                                int month = parse(s, n.children()[2]);
                                int day = parse(s, n.children()[4]);
                                Calendar c = Calendar.getInstance();
                                c.set(Calendar.YEAR, year);
                                c.set(Calendar.MONTH, month);
                                c.set(Calendar.DATE, day);
                                return c.get(Calendar.YEAR) == year &amp;&amp; c.get(Calendar.MONTH) == month &amp;&amp; c.get(Calendar.DATE) == day;
                        }

                        private int parse(CharSequence s, Match n) {
                                return Integer.parseInt(s.subSequence(n.start(), n.end()).toString());
                        }
                });
                String s = "2012/13/41 2001/1/1";
                Options opt = new Options();
                opt.allowOverlap(true);
                Matcher m = g.find(s, opt);
                Match n;
                while ((n = m.match()) != null)
                        System.out.println(n.group());</pre>
		produces
		<pre class="results">2001/1/1</pre>
	</div>
	<div>
		This is obviously a somewhat silly example as it is practically no
		different from post-filtering the results without the condition, but
		it does illustrate the process. Within the grammar rules you only name
		the condition. After grammar compilation you assign to this name an
		extension of the abstract class
		<code>dfh.grammar.Condition</code>
		. In complex grammars conditions can cause spurious matches to fail
		quickly, accelerating the discovery of real matches. Also, they
		enforce a declarative style which makes the logic of the grammar
		easier to follow.
	</div>
</body>
</html>
